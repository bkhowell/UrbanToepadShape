#clear all current variables or functions from R memory and start (or restart) script/anayses
rm(list = ls(all = TRUE)) 

###### Howell Puerto Rican Anole Toe Pad Shape Methadological Analyses ######

  #To our knowledge, this study is the first time geometric morphometics have been used to investigate lizard toe pad shape
  #As a result, we conducted a series of analyses to investigate methodological aspects of this approach. 
  #Specifically, we asked:
    #How well do geometric morphometric related values (landmark area and centroid size) serve as proxies of pad area?
    #How well does calculating a convex hull polygon area around landmarks 3,4, 5,6, and 7,8 and connecting semilandmarks approximate toe pad area?
    #Are there size related aspects of shape in our data? and do PC axes capture size related shape as they typically do?

  ## Please run the "Howell PR Preliminary Data Setup.R" script prior to this script.
  ## It generates the required "Howell R data.Rdata" file needed for these analyses

## Necessry files for this R script

  # Howell R data.Rdata - generated by the "Howell PR Preliminary Data Setup.R" script 

## Packages used in this script 

  #library(geomorph)
  packageVersion("geomorph")
  #3.3.1

  #library(pracma)
  packageVersion("pracma")
  #2.2.9


## Custom functions used in this script 
  
  # Compare_shape() - plots a side by side comparison of two shape variables 

## My Current R and RStudio Versions 

  #check version of R
  getRversion()
  #R version 3.5.3

  #check R studio version
  require(rstudioapi)
  versionInfo()$version
  #RStudio version 1.1.463

######
###### Comparing Measurements of Size/Area ######

#In these analysess, we are curious how well our measurements of area from ImageJ (measuring pad to the lower joint), a convex hull around our landmarks, and centroid size correlate 
#Centroid size is the square root of the sum of the squared distances of all landmarks from their centroid (ie center)

#Load geomoprh libary
library(geomorph)

#Set working directory
### CHANGE THIS if not already in working directory ###
setwd("UrbanToepadShape")
  
load(file="Howell R data.Rdata") #Load the previously generated data file. 

#Save the imported datasets to their own objects
dat.raw<-Howell_dat$dat.raw
dat.super<-Howell_dat$dat.super
dat.field<-Howell_dat$dat.field 

#Set relevant variables as factors 
dat.field$Habitat_Category<-as.factor(dat.field$Habitat_Category)
dat.field$Municipality<-as.factor(dat.field$Municipality)


#check to make sure the individuals in GM data (dat.raw and dat.super) and dat.field are in the same order 
dat.field$Specimen == dimnames(dat.raw)[[3]] #yes they are
dat.field$Specimen == dimnames(dat.super$coords)[[3]] #yes they are


#here is an exmaple of calculating centroid size by hand to make sure we understand how its calculated 
if(FALSE){
  centroid<-c(mean(dat.raw[,1,1]), mean(dat.raw[,2,1]))
  distances2<-matrix(nrow = nrow(dat.raw[,,1]), ncol = 1)


  for(r in 1:nrow(dat.raw[,,1])){
    #r<-1
    distances2[r,]<-sqrt(((dat.raw[r,1,1]-centroid[1])^2)+((dat.raw[r,2,1]-centroid[2])^2)) #equation to calculate distance from 2 points 
    distances2[r,]<-(distances2[r,])^2 #square the distances 
  }

  dat.super$Csize[1]==sqrt(sum(distances2))
}


#make a new object to hold each individual's estimated convex hull area
ConvexHullArea<-matrix(nrow = nrow(dat.field), ncol=1)
rownames(ConvexHullArea)<-dat.field$Specimen

library (pracma)
#The 'polyarea' function needs points to be listed in a counter clockwise order
#starting with the lower left vertex, otherwise the area can be negative and the estimated center point can we weird
#The landmarks outlining the pad are 3,4 (lower left and right), 5,6, (widest left and right), and 7,8 (distal left and right)
#the order of the landmarks needs to be 3,4,6,8,7,5
#There are no semilandmarks connecting 3 to 4
#Landmarks connecting landmark 4 to 6 are semilandmark points 75-68 (note the reverse order)
#Landmarks connecting landmark 6 to 8 are semilandmark points 67-60 (note the reverse order)
#There are no semilandmarks connecting 8 to 7 
#Landmarks connecting landmark 7 to 5 are semilandmark points 43-36 (note the reverse order)
#Landmarks connecting landmark 5 to 3 are semilandmark points 35-28 (note the reverse order)

#Here is the order I'm listing the pad landmarks for the 'polyarea' function: 
#c(3,4, 75:68, 6, 67:60, 8,7, 43:36, 5, 35:28)

#plot this order to double check its correct 
plot(dat.raw[,,1], pch=19, asp=1, col="gray") #just using indiviudal 1 as an exmaple 

#text(dat.raw[,,1], paste(1:nrow(dat.raw[,,1])), cex=0.5)
points(dat.raw[c(3,4, 75:68, 6, 67:60, 8,7, 43:36, 5, 35:28),,1], pch=19, col=rainbow(n=40))

arrows(dat.raw[3,1,1], dat.raw[3,2,1], dat.raw[4,1,1], dat.raw[4,2,1], length=0.1) #pt 3 to 4
arrows(dat.raw[4,1,1], dat.raw[4,2,1], dat.raw[6,1,1], dat.raw[6,2,1], length=0.1) #pt 4 to 6
arrows(dat.raw[6,1,1], dat.raw[6,2,1], dat.raw[8,1,1], dat.raw[8,2,1], length=0.1) #pt 6 to 8
arrows(dat.raw[8,1,1], dat.raw[8,2,1], dat.raw[7,1,1], dat.raw[7,2,1], length=0.1) #pt 8 to 7
arrows(dat.raw[7,1,1], dat.raw[7,2,1], dat.raw[5,1,1], dat.raw[5,2,1], length=0.1) #pt 7 to 5
arrows(dat.raw[5,1,1], dat.raw[5,2,1], dat.raw[3,1,1], dat.raw[3,2,1], length=0.1) #pt 5 to 3

#Hopefully with the toes being unaligned and at different angles, starting with point 3, which should usually be in the lower left will be ok
#but this is something to keep an eye on

for (i in 1:nrow(ConvexHullArea)){
  #i<-1
  ConvexHullArea[i,]<-polyarea(dat.raw[c(3,4, 75:68, 6, 67:60, 8,7, 43:36, 5, 35:28),1,i], dat.raw[c(3,4, 75:68, 6, 67:60, 8,7, 43:36, 5, 35:28),2,i])
  
}

#test for for correlations between centroid size and area from imageJ


#test for for correlations between centroid size and area from imageJ
cor.test(log(dat.field[,"Area_mm2"]), log(dat.super$Csize), method="pearson") 
#t = 34.749, df = 244, p-value < 2.2e-16 corr = 0.912083
out<-summary(aov(log(dat.super$Csize)~log(dat.field[,"Area_mm2"])))
out[[1]][1,"Pr(>F)"] #1.854127e-96


#test for for correlations between landmark convex hull area and area from imageJ
cor.test(log(dat.field[,"Area_mm2"]), log(ConvexHullArea), method="pearson") 
#t = 58.148, df = 244, p-value < 2.2e-16 corr = 0.9657602

out<-summary(aov(log(ConvexHullArea)~log(dat.field[,"Area_mm2"])))
out[[1]][1,"Pr(>F)"] #5.575995e-145

#estimate slope of estimate how much larger our image measurements are
lm(ConvexHullArea~dat.field[,"Area_mm2"])$coefficients["dat.field[, \"Area_mm2\"]"]
#0.777419
lm(ConvexHullArea~dat.field[,"Area_mm2"])$coefficients["(Intercept)"]
#-0.08104741
#so area based on landmark polygons are ~78% of area from ImageJ (down to the joint) ignoring the non-zero y-intercept



#also ask how centroid size might be related to shape
#Calculate relative toe pad widths (using unaligned landmarks)
widths<-matrix(nrow = dim(dat.raw)[3], ncol = 1)
for(r in 1:dim(dat.super$coords)[3]){
  #r<-1
  w<-dist(dat.raw[5:6,,r], method = "euclidean")
  widths[r,]<-w
  
}

#Calculate relative toe length (using unaligned landmarks)
lengths<-matrix(nrow = dim(dat.raw)[3], ncol = 1)
for(r in 1:dim(dat.raw)[3]){
  #r<-1
  pt1<-apply(dat.raw[1:2,,r], MARGIN=2, FUN = mean) #center of toe base (average of landamrks 1 and 2)
  l<-dist(rbind(pt1, dat.raw[9,,r]), method = "euclidean")
  lengths[r,]<-l
  
}


rownames(widths)<-dimnames(dat.raw)[[3]]
rownames(lengths)<-dimnames(dat.raw)[[3]]

proportions<-widths/lengths



#test for for correlations between centroid size~area residuals and toe W/L proportions
Csize_res<-lm(log(dat.super$Csize)~log(dat.field[,"Area_mm2"]))$res

out<-lm(Csize_res~proportions)
summary(out)
out$coefficients["(Intercept)" ]  #0.2168499 intercept
out$coefficients["proportions" ] #-1.489979 slope
summary(out)$coefficients["(Intercept)","Pr(>|t|)"] #intercept Pval 1.242658e-14
summary(out)$coefficients["proportions","Pr(>|t|)"] #slope Pval 9.405575e-15


#make plots 
pdf(file=file.path("Output/Plots/Methodological/GM vs Area.pdf"), width=4, height=8)
par(mfrow=c(2,1),mar=c(4,4,0,0.5), pty="s") 

#centroid size vs imageJ area
plot(dat.field$Area_mm2, dat.super$Csize, pch=19, col="grey", xlab=NA, ylab=NA, xlim=c(0,12), ylim=c(0, 40), xaxt="n")
mtext(expression(paste("Pad Area (mm"^"2",")")), side=1, line=2.5, cex=1.5)
mtext("to joint in ImageJ", side=1, line=3.1, cex=1)

mtext("Centroid Size (mm)", side=2, line=2.5, cex=1.5)
abline(lm(dat.super$Csize~dat.field[,"Area_mm2"]), lwd=2)
axis(side = 1, at = c(0,2,4,6,8,10,12), padj = -0.8)

text(x=-0.5, y=40, paste("Pearson's R = ", round(cor.test(log(dat.field[,"Area_mm2"]), log(dat.super$Csize), method="pearson")$estimate, 2)), pos=4, cex=0.8) #corr = 0.912083
text(x=-0.5, y=38, paste("p < 0.001 "), pos=4, cex=0.8)

segments(dat.field$Area_mm2, predict(lm(dat.super$Csize~dat.field$Area_mm2)), dat.field$Area_mm2, predict(lm(dat.super$Csize~dat.field$Area_mm2))+lm(dat.super$Csize~dat.field$Area_mm2)$res)



#GM convex hull area vs imageJ area
plot(dat.field$Area_mm2, ConvexHullArea, pch=19, col="grey", xlab=NA, ylab=NA, xlim=c(0,12), ylim=c(0,12), xaxt="n", asp=1)
mtext(expression(paste("Pad Area (mm"^"2",")")), side=1, line=2.5, cex=1.5)
mtext("to joint in ImageJ", side=1, line=3.1, cex=1)

mtext(expression(paste("Landmark Polygon Area (mm"^"2",")")), side=2, line=2, cex=1.5)
abline(lm(ConvexHullArea~dat.field[,"Area_mm2"]), lwd=2)
axis(side = 1, at = c(0,2,4,6,8,10,12), padj = -0.8)
abline(a = 0, b = 1, lty=2)

text(x=-0.5, y=12, paste("Pearson's R = ", round(cor.test(log(dat.field[,"Area_mm2"]), log(ConvexHullArea), method="pearson")$estimate, 2)), pos=4, cex=0.8) #corr = 0.9657602
text(x=-0.5, y=11.35, paste("p < 0.001 "), pos=4, cex=0.8)

dev.off()


#centroid size~area residuals vs W/L proportions insert plot
pdf(file=file.path("Output/Plots/Methodological/Csize res vs W-L.pdf"),  width=4, height=4)
par(mar=c(3,4,0,0.5), pty="s") 

plot(proportions, Csize_res, pch=19, col="grey", xlab=NA, ylab=NA, cex.axis=0.9)
mtext("Toe Width/Length", side=1, line=2.5, cex=1.5)
mtext("Centroid Size Residuals", side=2, line=2, cex=1.5)
abline(lm(Csize_res~proportions))
abline(h=0, lty=2)

text(x=0.14, y=0.15, paste("slope  = ",round(lm(Csize_res~proportions)$coefficient["proportions"], 2), ", p < 0.001", sep=""), pos=4, cex=0.8)
text(x=0.14, y=0.13, paste("intercept = ",  round(lm(Csize_res~proportions)$coefficient["(Intercept)"], 2), ", p < 0.001", sep=""), pos=4, cex=0.8)

dev.off()


#remove variables we no logner need 
rm(Howell_dat)
rm(lengths)
rm(widths)
rm(proportions)
rm(Csize_res)
rm(i)
rm(l)
rm(r)
rm(w)
rm(pt1)


###### ImageJ Pad Area Excluding Lower Joint vs Landmark Area Subset ######

#Using a more conservative measurement of toe pad area, only outlining the enlarged area of the pad in ImageJ
#we compared this area to the area captured within landmarks 3-8, including the connecting semilandmarks to
#test if landmark area could be used to accureltly measure toe pad area 

#Import field data
#This file should be in the same working diretory as all the other files we've used so far
dat.area<-read.delim("Data/Howell Pad Area Subset.txt", as.is = T, header=T) #as.is=T to prevent R from automatically assigning text variable as factors, header=T to automatically assign column names

#Confirm that the specimen names in our imported area data are somewhere within our landmark data and field data
dat.area$Specimen %in% dat.field$Specimen
dat.area$Specimen %in% rownames(ConvexHullArea)
#should all be true

#Since we're only using a subset of individuals, we need to make new matching subsets of our other data to match
dat.sub.field<-dat.field
rownames(dat.sub.field)<-dat.field$Specimen
dat.sub.field<-dat.sub.field[dat.area$Specimen, "Area_mm2"]
names(dat.sub.field)<-dat.area$Specimen

dat.sub.ConvexHull<-ConvexHullArea[dat.area$Specimen,]


names(dat.sub.field)==dat.area$Specimen
names(dat.sub.ConvexHull)==dat.area$Specimen
#now we have subsets of our previous area measurements to the knuckle (dat.sub.field) and our landmark based area measurements (dat.sub.ConvexHull)



#statistically compare area measured from photos to convex hull area 
out<-t.test(x=dat.area$Area_mm2, y=dat.sub.ConvexHull, paired=T)
out #yes, the means are signifincalty different 
#t = -15.585, df = 65, p-value < 2.2e-16
out$statistic #t value -15.58549 
out$parameter #df 65
out$p.value  # 1.229182e-23

out$estimate # mean difference -0.2910069

cor.test(dat.area$Area_mm2, dat.sub.ConvexHull, method="pearson") #corr = 0.9925967
out<-lm(dat.sub.ConvexHull~dat.area$Area_mm2)
out$coefficients["(Intercept)" ]  #0.2477301 intercept
out$coefficients["dat.area$Area_mm2" ] #1.009501 slope



#get 95% confidence intervals 
mean(dat.area$Area_mm2)  # 4.555061
CI<-t.test(dat.area$Area_mm2, conf.level = 0.95)$conf.int[1:2]
abs((CI[1]-CI[2])/2) #0.3009916 95% CI

mean(dat.sub.ConvexHull)  # 4.846068
CI<-t.test(dat.sub.ConvexHull, conf.level = 0.95)$conf.int[1:2]
abs((CI[1]-CI[2])/2) #0.3061176 95% CI



#plot imageJ area vs GM area 
pdf(file=file.path("Output/Plots/Methodological/SubArea vs ConvexHull.pdf"),  width=4.5, height=4.5)
par(mar=c(5,4,2,0.5), pty="s") 

plot(dat.area$Area_mm2, dat.sub.ConvexHull, asp=1, xlim=c(0,12), ylim=c(0,12), pch=19, col="grey", xaxt="n", xlab=NA, ylab=NA)
abline(a = 0, b=1, lty=2)

abline(lm(dat.sub.ConvexHull~dat.area$Area_mm2))

mtext(expression(paste("Pad Area (mm"^"2",")")), side=1, line=2.5, cex=1.5)
mtext("only pad in ImageJ", side=1, line=3.1, cex=1)

mtext(expression(paste("Landmark Polygon Area (mm"^"2",")")), side=2, line=2, cex=1.5)
axis(side = 1, at = c(0,2,4,6,8,10,12), padj = -0.8)

text(x=-0.5, y=12, paste("slope  = ",round(lm(dat.sub.ConvexHull~dat.area[,"Area_mm2"])$coefficient["dat.area[, \"Area_mm2\"]"], 2)), pos=4, cex=0.8)
text(x=-0.5, y=11.25, paste("intercept = ",  round(lm(dat.sub.ConvexHull~dat.area[,"Area_mm2"])$coefficient["(Intercept)"], 2)), pos=4, cex=0.8)
text(x=-0.5, y=10.5, paste("Pearson's R = ", round(cor.test(dat.area[,"Area_mm2"], dat.sub.ConvexHull, method="pearson")$estimate, 2)), pos=4, cex=0.8) 

out<-t.test(x=dat.area$Area_mm2, y=dat.sub.ConvexHull, paired=T)
text(x=-0.5, y=9.75, paste("t(", round(out$parameter, 1), ") = ", round(out$statistic, 2), ", p < 0.001", sep=""), pos=4, cex=0.8)

dev.off()




#plot to show how much each individual shifted 

pdf(file=file.path("Output/Plots/Methodological/SubArea vs ConvexHull Shifts.pdf"),  width=4, height=4)
par(mar=c(4,4.5,0.5,0.5), pty="s") 


plot(dat.area$Area_mm2, dat.sub.ConvexHull-dat.area$Area_mm2, ylim=c(-1,1), pch=19, col="grey", ylab=NA, xlab=NA, cex.axis=0.9)
abline(h=0, lty=2)
abline(lm((dat.sub.ConvexHull-dat.area$Area_mm2)~dat.area$Area_mm2))
mtext(expression(paste("Pad Area (mm"^"2",")")), side=1, line=2.5, cex=1.5)
mtext("only pad in ImageJ", side=1, line=3.1, cex=1)

mtext("Polygon Area - ImageJ Area", side=2, line=3.2, cex=1.5)
mtext(expression(paste("(mm"^"2",")")), side=2, line=1.5, cex=1.5)

dev.off()



#remove variables we no logner need 
rm(dat.area)
rm(out)
rm(CI)
rm(dat.sub.ConvexHull)
rm(dat.sub.field)



###### Size Related Aspets of Shape #####

#We are also insterested in descibing potential correlations between sample size and shape. 
#Using geomorph's procD function, we can correlate shape wth toe pad area and centroid size
#We can also use the shape.predictor function to visualize these shapes 

## Does toe pad shape correlate with different measuremnts of size (ie toe pad area or centroid size)? 

#Build a geomorph data frame
gdf <- geomorph.data.frame(Coords=dat.super$coords, Area = log(dat.field$Area_mm2), Csize = log(dat.super$Csize))

#Does toe pad area or centroid size predcit shape? SS.type="II" denotes the use of a type II sum of squares
fit<-procD.lm(Coords~Area*Csize, data = gdf, SS.type="II") 
summary(fit) 

## both variables but not the interaction were significant (p=0.001 for two variables, p = 0.177 for the interaction)


#We now run a custom function to plot and compare shape data
### MUST LOAD FUNCTION ###
#Run the Compare_shape() function

###### FUNCTION Compare_shape() - plots two shapes side by side for visual comparison   ####

## Arguments
# shape_urb - mean shape of urban specimens (only the "matrix" data from the mshape() function)
# shape_nat - mean shape of forest specimens (only the "matrix" data from the mshape() function)
# spread - a numeric value to control the horizontal spacing of the two shapes

Compare_shape<-function(shape_nat, shape_urb, col_nat_lt, col_nat_dk, col_urb_lt, col_urb_dk, spread){
  
  #shape_urb<-mshape_urban.raw[]
  #shape_nat<-mshape_forest.raw[]
  #spread<- 1.5
  
  #This function is built color in our specimens, and so assumes our specific landmark structure
  #This could easily be changed to work with a different landmark structure
  #This function aligns the two specimens vertically using landmark 3 and 4
  
  #col_nat_lt assigns the lighter color of the left toepad
  #col_nat_dk assigns the darker color of the left toepad
  #col_urb_lt assigns the lighter color of the right toepad
  #col_urb_dk assigns the darker color of the right toepad
  
  # shift landmarks vertically to align landmark 3 and 4 with 0 on the Y axis
  #plot(shape_urb, asp=1)
  vert_shift<-0-mean(shape_urb[3:4,2])
  shape_urb[,2]<-shape_urb[,2]+vert_shift
  
  #plot(shape_nat, asp=1)
  vert_shift<-0-mean(shape_nat[3:4,2])
  shape_nat[,2]<-shape_nat[,2]+vert_shift
  
  
  #shift landmarks horizontally left and right of 0 on the x axis to set the distance between the specimens (+spread and -spread)
  
  #plot(shape_urb, asp=1)
  shape_urb[,1]<-shape_urb[,1]+spread
  
  #plot(shape_nat, asp=1)
  shape_nat[,1]<-shape_nat[,1]-spread
  
  
  #plot the shapes
  plot(x=c(shape_urb[,1], shape_nat[,1]), y=c(shape_urb[,2], shape_nat[,2]), asp=1, col="white", xlab=NA, ylab=NA, xaxt="n", yaxt="n", bty="n") #plot an empty plot with the correct dimensions 
  
  #add a grid to the background of the plot
  if (spread==1.5) {
    abline (v=c(seq(-5, 5, by=0.5)), col = "darkgrey", lty = "dotted")
    abline (h=c(seq(-10, 10, by=0.5)), col = "darkgrey", lty = "dotted")
  }
  if (spread==0.05) {
    abline (v=c(seq(-0.2, 0.2, by=0.02)), col = "darkgrey", lty = "dotted")
    abline (h=c(seq(-0.3, 0.3, by=0.02)), col = "darkgrey", lty = "dotted")
  }
  
  
  #alignment line showing the vertical alignment of landmarks 3 and 4
  segments(x0 = mean(shape_urb[3:4,1]), y0=0, x1=mean(shape_nat[3:4,1]), y1=0, lty=2)
  #plot lines showing the top of both pads (landmarks 7 and 8)
  segments(x0 = mean(shape_urb[7:8,1]), y0=mean(shape_urb[7:8,2]), x1=mean(shape_urb[7:8,1])-(2*spread), y1=mean(shape_urb[7:8,2]), lty=1, lwd=2, col=col_urb_lt)
  segments(x0 = mean(shape_nat[7:8,1]), y0=mean(shape_nat[7:8,2]), x1=mean(shape_nat[7:8,1])+(2*spread), y1=mean(shape_nat[7:8,2]), lty=1, lwd=2, col=col_nat_dk)
  
  outline_points<-c(1,20:27,3,28:35,5,36:43,7,44:51,9,52:59,8,60:67,6,68:75,4,76:83,2) #to define the outline of our toe
  pad_points<-c(3,28:35,5,36:43,7,8,60:67,6,68:75,4) #to define the outline of our pad
  lamellae_points1<-c(10, 84:91, 11) #to define the points of each lamellae curve
  lamellae_points2<-c(12, 92:99, 13)
  lamellae_points3<-c(14, 100:107, 15)
  lamellae_points4<-c(16, 108:115, 17)
  lamellae_points5<-c(18, 116:123, 19)
  
  polygon(shape_urb[outline_points,], border=NA, col=col_urb_lt)
  polygon(shape_urb[pad_points,], border=NA, col=col_urb_dk)
  points(shape_urb[1:9,], pch=19, cex=0.5)
  
  points(shape_urb[10:19,], pch=19, cex=0.2)
  points(shape_urb[lamellae_points1,], type = "l")
  points(shape_urb[lamellae_points2,], type = "l")
  points(shape_urb[lamellae_points3,], type = "l")
  points(shape_urb[lamellae_points4,], type = "l")
  points(shape_urb[lamellae_points5,], type = "l")
  
  
  ###shape nat
  polygon(shape_nat[outline_points,], border=NA, col=col_nat_lt)
  polygon(shape_nat[pad_points,], border=NA, col=col_nat_dk)
  points(shape_nat[1:9,], pch=19, cex=0.5)
  
  points(shape_nat[10:19,], pch=19, cex=0.2)
  points(shape_nat[lamellae_points1,], type = "l")
  points(shape_nat[lamellae_points2,], type = "l")
  points(shape_nat[lamellae_points3,], type = "l")
  points(shape_nat[lamellae_points4,], type = "l")
  points(shape_nat[lamellae_points5,], type = "l")
  
  
}


#This function produces a .pdf plot file comparing two shapes side by side. You must have a destination folder already in place to receive these .pdf plots
#I use the folder "Plots" within our "Output" folder in the to receive these plots  


#Visualize shape related to these two variables of size
#First visualize shape variation that correlates with log(Area)
fit<-procD.lm(Coords~Area, data = gdf) 
summary(fit) 

allom.plot <- plot(fit, type = "regression", predictor = gdf$Area, reg.type ="RegScore") 
preds <- shape.predictor(fit$GM$fitted, x= allom.plot$RegScore, Intercept = FALSE, predmin = min(allom.plot$RegScore), predmax = max(allom.plot$RegScore)) 

#rotate the projected shapes to be vertical 
predmin<-rotate.coords(preds$predmin, type = "rotateCC") # the argument rotateCC rotates each matrix 90 deg counter clockwise
predmax<-rotate.coords(preds$predmax, type = "rotateCC") # the argument rotateCC rotates each matrix 90 deg counter clockwise


pdf(file = file.path("Output/Plots/Methodological/Size Shapes Area.pdf"))

Compare_shape(shape_nat = predmin, shape_urb = predmax, col_nat_lt = "tan", col_nat_dk = "burlywood4", col_urb_lt = "tan", col_urb_dk = "burlywood4", spread = 0.05)

legend(x=-0.02, y=-0.27, legend="More Area", bg = "white", bty = "o", box.col="white", xpd=T)
legend(x=-0.12,y=-0.27, legend="Less Area", bg = "white", bty = "o", box.col="white", xpd=T)

dev.off()


#Now visualize shape variation that correlates with log(centroid size)
fit<-procD.lm(Coords~Csize, data = gdf) 
summary(fit) 

allom.plot <- plot(fit, type = "regression", predictor = gdf$Csize, reg.type ="RegScore") 
preds <- shape.predictor(fit$GM$fitted, x= allom.plot$RegScore, Intercept = FALSE, predmin = min(allom.plot$RegScore), predmax = max(allom.plot$RegScore)) 

#rotate the projected shapes to be vertical 
predmin<-rotate.coords(preds$predmin, type = "rotateCC") # the argument rotateCC rotates each matrix 90 deg counter clockwise
predmax<-rotate.coords(preds$predmax, type = "rotateCC") # the argument rotateCC rotates each matrix 90 deg counter clockwise


pdf(file = file.path("Output/Plots/Methodological/Size Shapes Csize.pdf"))

Compare_shape(shape_nat = predmin, shape_urb = predmax, col_nat_lt = "tan", col_nat_dk = "burlywood4", col_urb_lt = "tan", col_urb_dk = "burlywood4", spread = 0.05)

legend(x=-0.02, y=-0.27, legend="    Larger \nCentroid Size", bg = "white", bty = "o", box.col="white", xpd=T)
legend(x=-0.13,y=-0.27, legend="    Smaller \nCentroid Size", bg = "white", bty = "o", box.col="white", xpd=T)

dev.off()



#remove variables we no logner need 
rm(allom.plot)
rm(ConvexHullArea)
rm(fit)
rm(gdf)
rm(predmax)
rm(predmin)
rm(preds)






###### PCA Correlations with Size ######

# We tested if PC 1,2,3 correlate with size, with size defined as SVL, natural log toe pad area (measured to the phalangeal joint), and natural log(centroid size)

PCAdat<-gm.prcomp(dat.super$coords) #plotTangentSpace deprecated in geomoprh version 3.3.1
PCscores<-PCAdat$x #PC scores represent each specimen's location on each PC axes


#first test how SVL is related to PC axes
dat.stat<-cbind(PCscores[,"Comp1"], PCscores[,"Comp2"], PCscores[,"Comp3"], log(dat.field$SVL_mm))
colnames(dat.stat)<-c("PC1", "PC2", "PC3", "SVL")
dat.stat<-data.frame(dat.stat)

PC1_out<-cor.test(dat.stat[,"SVL"], dat.stat[,"PC1"], method="pearson") 
PC1_out$p.value  #not sig p = 0.7777918
PC1_out$estimate  #r = 0.0180829

PC2_out<-cor.test(dat.stat[,"SVL"], dat.stat[,"PC2"], method="pearson") 
PC2_out$p.value  #sig p 8.842806e-05,
PC2_out$estimate #r = -0.2473168

PC3_out<-cor.test(dat.stat[,"SVL"], dat.stat[,"PC3"], method="pearson") 
PC3_out$p.value #sig p 1.723177e-11,
PC3_out$estimate #r = 0.4118543


#make plots to show relationships with PC 1-3
pdf(file=file.path("Output/Plots/Methodological/PC123 correlations SVL.pdf"), width=4, height = 10)
par(mfrow=c(3,1), mar=c(5,5,2,2)) 


plot(dat.stat[,"SVL"], dat.stat[,"PC1"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(45, 75)))
axis(side = 1, at = log(seq(45, 75, by=5)), labels = c("45", "50", "55", "60", "65", "70", "75"), cex.axis=1.5)
mtext("Principal Component Axis 1", side=2, line=1, cex=1.1)
mtext("SVL (mm)", side=1, line=3, cex=1.1)

lm.out<-lm(PC1~SVL, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(log(45), log(75),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(SVL=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(45), y=0.078, labels = paste("R = ", round(PC1_out$estimate, 3)), adj=0)
text(x=log(45), y=0.068, labels = paste("p  = ", round(PC1_out$p.value, 3)), adj=0)


plot(dat.stat[,"SVL"], dat.stat[,"PC2"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(45, 75)))
axis(side = 1, at = log(seq(45, 75, by=5)), labels = c("45", "50", "55", "60", "65", "70", "75"), cex.axis=1.5)
mtext("Principal Component Axis 2", side=2, line=1, cex=1.1)
mtext("SVL (mm)", side=1, line=3, cex=1.1)

lm.out<-lm(PC2~SVL, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(log(45), log(75),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(SVL=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(45), y=0.071, labels = paste("R = ", round(PC2_out$estimate, 3)), adj=0)
text(x=log(45), y=0.063, labels = paste("p  < 0.001"), adj=0)


plot(dat.stat[,"SVL"], dat.stat[,"PC3"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(45, 75))) 
axis(side = 1, at = log(seq(45, 75, by=5)), labels = c("45", "50", "55", "60", "65", "70", "75"), cex.axis=1.5)
mtext("Principal Component Axis 3", side=2, line=1, cex=1.1)
mtext("SVL (mm)", side=1, line=3, cex=1.1)

lm.out<-lm(PC3~SVL, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(log(45), log(75),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(SVL=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(45), y=0.058, labels = paste("R = ", round(PC3_out$estimate, 3)), adj=0)
text(x=log(45), y=0.05, labels = paste("p  < 0.001"), adj=0)


dev.off()


#we then considered how toe pad area measured to the nearest joint below the pad is related to PC axes
dat.stat<-cbind(PCscores[,"Comp1"], PCscores[,"Comp2"], PCscores[,"Comp3"], log(dat.field$Area_mm2))
colnames(dat.stat)<-c("PC1", "PC2", "PC3", "Area")
dat.stat<-data.frame(dat.stat)


PC1_out<-cor.test(dat.stat[,"Area"], dat.stat[,"PC1"], method="pearson") 
PC1_out$p.value #not sig p = 0.1282292
PC1_out$estimate #r = 0.09724849

PC2_out<-cor.test(dat.stat[,"Area"], dat.stat[,"PC2"], method="pearson") 
PC2_out$p.value #sig p = 3.950923e-05
PC2_out$estimate #-0.2589016

PC3_out<-cor.test(dat.stat[,"Area"], dat.stat[,"PC3"], method="pearson") 
PC3_out$p.value #sig p= 1.819038e-18
PC3_out$estimate #0.5203098


#make plots to show relationships with PC 1-3
pdf(file=file.path("Output/Plots/Methodological/PC123 correlations Area.pdf"), width=4, height = 10)
par(mfrow=c(3,1), mar=c(5,5,2,2)) 

plot(dat.stat[,"Area"], dat.stat[,"PC1"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(2,12)))
axis(side = 1, at = log(seq(2, 12, by=2)), labels = c("2", "4", "6", "8", "10", 12), cex.axis=1.5)
mtext("Principal Component Axis 1", side=2, line=1, cex=1.1)
mtext(expression(paste("Pad Area (mm"^"2",")")), side=1, line=3, cex=1.1)


lm.out<-lm(PC1~Area, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(min(dat.stat[,"Area"]),max(dat.stat[,"Area"]),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(Area=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(2), y=0.078, labels = paste("R = ", round(PC1_out$estimate, 3)), adj=0)
text(x=log(2), y=0.068, labels = paste("p  = ", round(PC1_out$p.value, 3)), adj=0)


plot(dat.stat[,"Area"], dat.stat[,"PC2"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(2,12)))
axis(side = 1, at = log(seq(2, 12, by=2)), labels = c("2", "4", "6", "8", "10", 12), cex.axis=1.5)
mtext("Principal Component Axis 2", side=2, line=1, cex=1.1)
mtext(expression(paste("Pad Area (mm"^"2",")")), side=1, line=3, cex=1.1)

lm.out<-lm(PC2~Area, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(min(dat.stat[,"Area"]),max(dat.stat[,"Area"]),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(Area=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(2), y=0.071, labels = paste("R = ", round(PC2_out$estimate, 3)), adj=0)
text(x=log(2), y=0.063, labels = paste("p  < 0.001"), adj=0)


plot(dat.stat[,"Area"], dat.stat[,"PC3"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(2,12)))
axis(side = 1, at = log(seq(2, 12, by=2)), labels = c("2", "4", "6", "8", "10", 12), cex.axis=1.5)
mtext("Principal Component Axis 3", side=2, line=1, cex=1.1)
mtext(expression(paste("Pad Area (mm"^"2",")")), side=1, line=3, cex=1.1)

lm.out<-lm(PC3~Area, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(min(dat.stat[,"Area"]),max(dat.stat[,"Area"]),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(Area=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(2), y=0.061, labels = paste("R = ", round(PC3_out$estimate, 3)), adj=0)
text(x=log(2), y=0.053, labels = paste("p  < 0.001"), adj=0)

dev.off()




#lastly, we considered how natlog centroid size is related to PC axes
dat.stat<-cbind(PCscores[,"Comp1"], PCscores[,"Comp2"], PCscores[,"Comp3"], log(dat.super$Csize))
colnames(dat.stat)<-c("PC1", "PC2", "PC3", "Csize")
dat.stat<-data.frame(dat.stat)


PC1_out<-cor.test(dat.stat[,"Csize"], dat.stat[,"PC1"], method="pearson") #not sig p = 0.1108132, r = 0.1019189
PC1_out$p.value
PC1_out$estimate

PC2_out<-cor.test(dat.stat[,"Csize"], dat.stat[,"PC2"], method="pearson") #sig p 1.069111e-05, r = -0.2766183
PC2_out$p.value
PC2_out$estimate

PC3_out<-cor.test(dat.stat[,"Csize"], dat.stat[,"PC3"], method="pearson") #sig p 3.463749e-09, r = 0.3654308
PC3_out$p.value
PC3_out$estimate


#make plots to show relationships with PC 1-3
pdf(file=file.path("Output/Plots/Methodological/PC123 correlations Csize.pdf"), width=4, height = 10)
par(mfrow=c(3,1), mar=c(5,5,2,2)) 


plot(dat.stat[,"Csize"], dat.stat[,"PC1"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(20,40)))
axis(side = 1, at = log(seq(20, 40, by=5)), labels = c("20", "25", "30", "35", "40"), cex.axis=1.5)
mtext("Principal Component Axis 1", side=2, line=1, cex=1.1)
mtext("Centroid Size", side=1, line=3, cex=1.1)


lm.out<-lm(PC1~Csize, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(min(dat.stat[,"Csize"]),max(dat.stat[,"Csize"]),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(Csize=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(20), y=0.078, labels = paste("R = ", round(PC1_out$estimate, 3)), adj=0)
text(x=log(20), y=0.068, labels = paste("p  = ", round(PC1_out$p.value, 3)), adj=0)


plot(dat.stat[,"Csize"], dat.stat[,"PC2"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(20,40)))
axis(side = 1, at = log(seq(20, 40, by=5)), labels = c("20", "25", "30", "35", "40"), cex.axis=1.5)
mtext("Principal Component Axis 2", side=2, line=1, cex=1.1)
mtext("Centroid Size", side=1, line=3, cex=1.1)

lm.out<-lm(PC2~Csize, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(min(dat.stat[,"Csize"]),max(dat.stat[,"Csize"]),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(Csize=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(20), y=0.071, labels = paste("R = ", round(PC2_out$estimate, 3)), adj=0)
text(x=log(20), y=0.063, labels = paste("p  < 0.001"), adj=0)


plot(dat.stat[,"Csize"], dat.stat[,"PC3"], pch=19, col="grey", ylab=NA, xlab=NA, cex=1.5, yaxt="n", xaxt="n", xlim=log(c(20,40)))
axis(side = 1, at = log(seq(20, 40, by=5)), labels = c("20", "25", "30", "35", "40"), cex.axis=1.5)
mtext("Principal Component Axis 3", side=2, line=1, cex=1.1)
mtext("Centroid Size", side=1, line=3, cex=1.1)

lm.out<-lm(PC3~Csize, data=dat.stat)
abline(lm.out, lwd=2)
newx = seq(min(dat.stat[,"Csize"]),max(dat.stat[,"Csize"]),by=0.1)
conf_interval <- predict(lm.out, newdata=data.frame(Csize=newx), interval="confidence", level = 0.95)
lines(newx, conf_interval[,2], lwd=2, lty=2)
lines(newx, conf_interval[,3], lwd=2, lty=2)

text(x=log(20), y=0.061, labels = paste("R = ", round(PC3_out$estimate, 3)), adj=0)
text(x=log(20), y=0.053, labels = paste("p  < 0.001"), adj=0)

dev.off()


#remove variables we no longer need 
rm(conf_interval)
rm(lm.out)
rm(PC1_out)
rm(PC2_out)
rm(PC3_out)
rm(PCAdat)
rm(PCscores)
rm(newx)


















